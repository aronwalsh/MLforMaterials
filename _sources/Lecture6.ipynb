{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HzUyhcHdn_E"
   },
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvlRkBnHdn_G"
   },
   "source": [
    "```{admonition} John von Neumann\n",
    ":class: tip\n",
    "If people do not believe that mathematics is simple, it is only because they do not realise how complicated life is.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJGDcDppdn_G"
   },
   "source": [
    "<iframe class=\"speakerdeck-iframe\" frameborder=\"0\" src=\"https://speakerdeck.com/player/66a1b93a85b143a1861630e7116ae1df\" title=\"Machine Learning for Materials (Lecture 6)\" allowfullscreen=\"true\" style=\"border: 0px; background-clip: padding-box; background-color: rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 420;\" data-ratio=\"1.3333333333333333\"></iframe>\n",
    "\n",
    "[Lecture slides](https://speakerdeck.com/aronwalsh/mlformaterials-lecture6-nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxK0Hmjqdn_G"
   },
   "source": [
    "## üî¨ Learning microstructure\n",
    "\n",
    "While chemical bonds and the unit cells of crystalline materials are defined at the nanometre scale, morphological features such as grains and voids emerge at the micron scale. \n",
    "\n",
    "Today, we will build our own perceptron model, interact with convolutional filters, and apply a deep learning model to probe the microstructure of materials. The arrangement and composition of atoms and grains within a material greatly influence its properties and performance. How these building blocks are arranged in a sample determines how strong, durable, or conductive it can be.\n",
    "\n",
    "## From perceptrons to neural networks\n",
    "\n",
    "The perceptron is a fundamental building block of artificial neural networks. Inspired by the way neurons in the brain work, a perceptron takes multiple inputs, applies weights to each input, sums them up, and passes the result through an activation function to produce an output. It is a binary classifier and can be trained to learn linear decision boundaries for simple classification tasks.\n",
    "\n",
    "The perceptron function can be represented mathematically as:\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "1, & \\text{if } \\sum_{i=1}^{n} w_i x_i + b > 0 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $f(x)$ represents the output of the perceptron for input $x$\n",
    "- $w_i$ are the weights associated with input features $x_i$\n",
    "- $b$ is the bias term\n",
    "- $n$ is the number of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation of libraries\n",
    "!pip install scikit-image --quiet\n",
    "!pip install torchvision --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChyamsJ-dn_G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import of modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1yYMYEHdn_H"
   },
   "source": [
    "Let's start with defining a perceptron function and understanding the input/output behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x096vH-qdn_H",
    "outputId": "8e707a40-05ab-4794-b9b4-7dbea82c6923",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the output of the perceptron\n",
    "  # Look how simple this model is!\n",
    "def perceptron(x1, x2, w1, w2):\n",
    "    weighted_sum + x1 * w1 + x2 * w2\n",
    "    return 1 if weighted_sum >= 0 else 0\n",
    "\n",
    "print (\"The output for (1,1,1,1) is\", perceptron(1,1,1,1))\n",
    "print (\"The output for (0,0,0,0) is\", perceptron(0,0,0,0))\n",
    "print (\"The output for (-1,0,1,0) is\", perceptron(-1,0,1,0))\n",
    "print (\"The output for (-1,0,-1,0) is\", perceptron(-1,0,-1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdOBgD8bdn_H"
   },
   "source": [
    "<details>\n",
    "<summary> Code hint </summary>\n",
    "You want to define `weighted_sum`, not add it to the inputs!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fMFXV1pdn_I"
   },
   "source": [
    "Below is a simple code, using `numpy` and `matplotlib`, to visualise the weighted inputs of a perceptron along with the predicted binary classification. In this dummy example for phase classification, the two input features $X_1$ and $X_2$ are named \"Scaled temperature\" and \"Scaled pressure\". There are two randomly initialised weights: $w_1$ and $w_2$. The perceptron will classify materials into two categories, \"Solid\" and \"Liquid\", based on these features and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "fcfsQUfvdn_I",
    "outputId": "9c8f1b25-6b25-4dd4-d392-f04201a2a0ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly assign weights for the features\n",
    "np.random.seed(42) # For reproducibility\n",
    "w1 = np.random.uniform(-1, 1)\n",
    "w2 = np.random.uniform(-1, 1)\n",
    "\n",
    "# Create data points for visualisation\n",
    "scaled_temperature = np.linspace(-1, 1, 100)\n",
    "scaled_pressure = np.linspace(-1, 1, 100)\n",
    "X1, X2 = np.meshgrid(scaled_temperature, scaled_pressure)\n",
    "predicted_labels = np.zeros_like(X1)\n",
    "\n",
    "# Apply the perceptron to classify data points\n",
    "   # This is where the perceptron function is called\n",
    "for i in range(len(scaled_temperature)):\n",
    "    for j in range(len(scaled_pressure)):\n",
    "        predicted_labels[i, j] = perceptron(scaled_temperature[i], scaled_pressure[j], w1, w2)\n",
    "\n",
    "# Plot a binary classification map\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.contourf(X1, X2, predicted_labels, alpha=0.5, levels=[-1, 0, 1], colors=('blue', 'orange'))\n",
    "plt.colorbar(ticks=[0, 1], label='Predicted Label')\n",
    "plt.scatter([-0.5], [0], c='blue', label='Liquid')\n",
    "plt.scatter([0.5], [0], c='orange', label='Solid')\n",
    "plt.xlabel('Scaled Temperature')\n",
    "plt.ylabel('Scaled Pressure')\n",
    "plt.title('Perceptron Model Phase Diagram')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpYmZFx2dn_I"
   },
   "source": [
    "<details>\n",
    "<summary> Why do we set a random seed?</summary>\n",
    "np.random() generates pseudorandom numbers. The algorithm starts with an initial seed value and then produces a sequence of numbers that appears random. However, since the process is deterministic, providing the same seed will result in the same sequence of \"random\" numbers. 42 is simply a science fiction reference. \n",
    "</details>\n",
    "\n",
    "That was fun, but a lone perceptron is limited in terms of the behaviour it can represent. How could we simulate more realistic phase behaviour? Let's code a neural network!\n",
    "\n",
    "Here the sigmoid activation function is used, which can be represented mathematically as:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma(x)$ is the sigmoid function applied to input $x$\n",
    "- $e$ is the base of the natural logarithm\n",
    "\n",
    "The hidden layer of the model takes the weighted sum of inputs $x_1$ and $x_2$, applies the sigmoid activation function, and produces  `hidden_layer_output`. The output layer then takes this hidden layer output. It applies weights $v_1$ and $v_2$ to produce the final `output_layer_input`, which is passed through the sigmoid activation function to obtain the predicted phase probabilities.\n",
    "\n",
    "This pseudo phase diagram shows the probability of the material being in the solid phase (orange region) or the liquid phase (blue region) based on the inputs `scaled_temperature` and `scaled_pressure`. The neural network learns from the data and tries to separate the two phases based on their properties.\n",
    "\n",
    "This is a toy model and in practice, you would use purpose-built packages such as `pytorch` to control the deep learning architecture and need a significant amount of reliable labelled data to train the network effectively, but following the same logic of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1eeLmPadn_I",
    "outputId": "67caa431-0414-4a04-80c8-3f186649ec53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid():\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "print (\"The output for (-1) is\", sigmoid(-1))\n",
    "print (\"The output for (0) is\", sigmoid(0))\n",
    "print (\"The output for (1) is\", sigmoid(1))\n",
    "print (\"The output for (10000) is\", sigmoid(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_XSulOHdn_I"
   },
   "source": [
    "<details>\n",
    "<summary> Code hint </summary>\n",
    "The sigmoid function needs an input, x. You can also trying different input values to get a feeling for how the function works.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "L1KBYtO-dn_I",
    "outputId": "976ff07b-dc98-40b3-833a-1d43da35680b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple example of data scaling, network architecture, and output visualisation\n",
    "\n",
    "# Function to scale data between -1 and 1\n",
    "def scale_data(data, min_val, max_val):\n",
    "    return 2 * (data - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "# Function to calculate the output of the two-layer neural network\n",
    "def neural_network(x1, x2, w1, w2, v1, v2):\n",
    "    hidden_layer_input = x1 * w1 + x2 * w2\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    output_layer_input = hidden_layer_output * v1 + x2 * v2\n",
    "    return sigmoid(output_layer_input)\n",
    "\n",
    "# Temperature and pressure range\n",
    "temperature_range = np.linspace(0, 100, 100)  # Temperature in Celsius\n",
    "pressure_range = np.linspace(0, 1000, 100)    # Pressure in atm\n",
    "\n",
    "# Scale the temperature and pressure to [-1, 1]\n",
    "scaled_temperature = scale_data(temperature_range, min(temperature_range), max(temperature_range))\n",
    "scaled_pressure = scale_data(pressure_range, min(pressure_range), max(pressure_range))\n",
    "\n",
    "# Randomly assign weights for the input and hidden layers\n",
    "w1 = np.random.uniform(-1, 1)\n",
    "w2 = np.random.uniform(-1, 1)\n",
    "v1 = np.random.uniform(-1, 1)\n",
    "v2 = np.random.uniform(-1, 1)\n",
    "\n",
    "# Create data points for visualisation\n",
    "X1, X2 = np.meshgrid(scaled_temperature, scaled_pressure)\n",
    "predicted_phases = np.zeros_like(X1)\n",
    "\n",
    "# Apply the neural network to predict phases\n",
    "for i in range(len(scaled_temperature)):\n",
    "    for j in range(len(scaled_pressure)):\n",
    "        predicted_phases[i, j] = neural_network(scaled_temperature[i], scaled_pressure[j], w1, w2, v1, v2)\n",
    "\n",
    "# Plot the \"phase diagram\"\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.contourf(temperature_range, pressure_range, predicted_phases, alpha=0.5, levels=np.linspace(0, 1, 11), cmap='coolwarm')\n",
    "plt.colorbar(label='Phase Probability')\n",
    "plt.xlabel('Temperature (¬∞C)')\n",
    "plt.ylabel('Pressure (atm)')\n",
    "plt.title('Two-Layer NN: Phase Diagram of Crystal X')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyl3gqywdn_J",
    "tags": []
   },
   "source": [
    "## Image processing\n",
    "\n",
    "Many characterisation techniques in materials science produce image data. Researchers can save time and perform advanced experiments (e.g. active learning) and analysis (e.g. feature identification) using codes. While \"point and click\" software solutions exist for image processing, they are often expensive and difficult to customise and automate for large datasets.\n",
    "\n",
    "Let's start by considering three classical convolutional filters:\n",
    "\n",
    "1. **Gaussian**\n",
    "   - Smoothes an image by reducing noise.\n",
    "   - Blurs the image by applying a weighted average to pixels.\n",
    "   - Kernel:\n",
    "     ```\n",
    "     1  2  1\n",
    "     2  4  2\n",
    "     1  2  1\n",
    "     ```\n",
    "\n",
    "2. **Sobel**\n",
    "   - Highlights edges and contours in an image.\n",
    "   - Computes gradient magnitude using convolutional kernels.\n",
    "   - Sobel Horizontal Kernel:\n",
    "     ```\n",
    "     -1  0  1\n",
    "     -2  0  2\n",
    "     -1  0  1\n",
    "     ```\n",
    "   - Sobel Vertical Kernel:\n",
    "     ```\n",
    "     -1 -2 -1\n",
    "      0  0  0\n",
    "      1  2  1\n",
    "     ```\n",
    "     \n",
    "3. **Laplacian**\n",
    "   - Emphasizes rapid intensity changes (edges).\n",
    "   - Calculates the second derivative to highlight inflection points.\n",
    "   - Laplacian Kernel:\n",
    "     ```\n",
    "      0  1  0\n",
    "      1 -4  1\n",
    "      0  1  0\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "c6McDt3Odn_J",
    "outputId": "7808b86f-814b-4f97-c035-44f5af64ef04",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage import io, color, filters\n",
    "\n",
    "# Load an example image (you can replace this with your own image)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/5/5e/AlubronzeCuAl20v500.png\"\n",
    "image = io.imread(image_url)\n",
    "gray_image = color.rgb2gray(image)\n",
    "\n",
    "# Apply classical image filters\n",
    "gaussian_filtered = filters.gaussian(gray_image, sigma=10.0)\n",
    "sobel_filtered = filters.sobel(gray_image)\n",
    "laplacian_filtered = filters.laplace(gray_image)\n",
    "\n",
    "# Plot the original and filtered images\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(gaussian_filtered, cmap='gray')\n",
    "plt.title('Gaussian Filter')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(sobel_filtered, cmap='gray', vmin=0, vmax=0.2)  # Adjust vmin and vmax as needed\n",
    "plt.title('Sobel Filter')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(laplacian_filtered, cmap='gray', vmin=-0.02, vmax=0.02)  # Adjust vmin and vmax as needed\n",
    "plt.title('Laplacian Filter')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF6D1oVHdn_J"
   },
   "source": [
    "<details>\n",
    "<summary> Code hint </summary>\n",
    "You can add your own image link and see the result.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwMEx1Hedn_J",
    "tags": []
   },
   "source": [
    "### Custom convolutional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xep7i5ndn_J"
   },
   "source": [
    "We are not limited to pre-built kernels. This code allows you to chose your own kernel matrix and includes an option for repeated convolutions, so you can apply the filter multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "fN8HzLHXdn_J",
    "outputId": "4c4728c1-04b0-4cc7-9f0e-e43c2ed6fe74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Load an example image (you can replace this with your own image)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/5/5e/AlubronzeCuAl20v500.png\"\n",
    "image = io.imread(image_url)\n",
    "gray_image = color.rgb2gray(image)\n",
    "\n",
    "# Define a larger custom kernel for more noticeable effect\n",
    "custom_kernel = np.array([[-2, -1, 0],\n",
    "                          [-1, 1, 1],\n",
    "                          [0, 1, 2]])\n",
    "\n",
    "# Normalise the kernel to sum to 1\n",
    "custom_kernel = custom_kernel / np.sum(custom_kernel)\n",
    "\n",
    "# Apply custom kernel using convolution\n",
    "num_iterations = 1 # Number of times to apply the convolution\n",
    "\n",
    "custom_filtered = gray_image.copy()\n",
    "for _ in range(num_iterations):\n",
    "    custom_filtered = convolve(custom_filtered, custom_kernel)\n",
    "\n",
    "# Plot the original and filtered images\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(custom_filtered, cmap='gray')\n",
    "plt.title('Custom Filtered Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN-GPI21dn_K"
   },
   "source": [
    "<details>\n",
    "<summary> Code hint </summary>\n",
    "Adjust the kernel and the number of interations that the kernel is applied (`num_iterations`).   \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KDhQVvSdn_K"
   },
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs are a class of deep learning models designed for image analysis. We will now build a basic CNN architecture using the popular deep learning tool `pytorch`.\n",
    "\n",
    "We all know that scientists like to dress well üßë‚Äçüî¨. Let's make use of the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset that consists of a training set of 60,000 examples and a test set of 10,000 examples of clothing and accessories.\n",
    "\n",
    "### Fashionable CNN \n",
    "\n",
    "Pay attention to each of the steps involved in building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUmsX4DYdn_K",
    "outputId": "ccb50d51-ee90-49ec-e7ba-df247eb88651",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorch deep learning library\n",
    "import torch.nn as nn  # Neural network modules in PyTorch\n",
    "import torch.optim as optim  # Optimisation algorithms in PyTorch\n",
    "from torch.utils.data import Dataset, DataLoader  # PyTorch data loading utilities\n",
    "from torchvision import datasets  # Datasets for computer vision tasks\n",
    "from torchvision.transforms import ToTensor  # Image transformations in PyTorch\n",
    "\n",
    "# Step 1 - Data\n",
    "\n",
    "# Training set\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# FashionMNIST labels\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "# Plot a few examples\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UelLKWxSdn_K"
   },
   "source": [
    "Let's see if the model can classify unseen images. Don't get your hopes too high!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Model\n",
    "\n",
    "# Define the CNN architecture\n",
    "clas SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the parent class (nn.Module)\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()  # ReLU activation function\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()  # ReLU activation function\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
    "\n",
    "        # Flatten the output for the fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # First Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()  # ReLU activation function\n",
    "\n",
    "        # Second Fully Connected Layer (Output Layer)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output neurons for the 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "\n",
    "        # First Convolutional Layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # First Fully Connected Layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        # Second Fully Connected Layer (Output Layer)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x  # Return the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Code hint </summary>\n",
    "Your are defining a class, whereas Clas is a popular name in Sweden</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Train and Test\n",
    "\n",
    "# Note, this may take a couple of minutes to complete. \n",
    "# As you wait, you can pay attention to how the loss improves in time.\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx}/{len(train_dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images with their predicted and actual labels\n",
    "def show_predictions(model, dataloader, num_images=5):\n",
    "    model.eval()\n",
    "    images, predictions, targets = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            images.append(data.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            targets.append(target.cpu().numpy())\n",
    "\n",
    "    images = np.concatenate(images)\n",
    "    predictions = np.concatenate(predictions)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "    # Plot random predictions\n",
    "    indices = np.random.choice(len(images), num_images, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(5, 10))\n",
    "    for i, index in enumerate(indices, 1):\n",
    "        plt.subplot(num_images, 2, i)\n",
    "        plt.imshow(images[index][0], cmap='gray')\n",
    "        plt.title(f\"Predicted: {predictions[index]}, Actual: {targets[index]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Show predictions on the test set\n",
    "show_predictions(model, test_dataloader, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it perform well? Remember the labels were:\n",
    "```\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vF5XZpBdn_L",
    "tags": []
   },
   "source": [
    "### Learned filters\n",
    "\n",
    "We can analyse the filters that were learned for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "l2CewdWhdn_L",
    "outputId": "95229bec-3e1d-4534-891c-3a55909b9fa1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the weights of the first convolutional layer\n",
    "conv1_weights = model.conv1.weight.data.cpu()\n",
    "\n",
    "# Visualise learned filters\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i in range(4):  # Only the first four filters\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "\n",
    "    # Plot the image representation of the filter\n",
    "    filter_image = conv1_weights[i].numpy()[0]\n",
    "    plt.imshow(filter_image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Filter {i + 1}\")\n",
    "\n",
    "    # Display the matrix representation of the filter\n",
    "    print(f\"Filter {i + 1} weights:\")\n",
    "    print(conv1_weights[i][0].numpy())\n",
    "    print()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQopxGXudn_L",
    "tags": []
   },
   "source": [
    "## Synthetic microscopy data\n",
    "\n",
    "For the exercise, we are going to generate some of our own characterisation data for training. You can imagine that this represents a spatially varying composition or structure, which you could measure with techniques such as Energy-dispersive X-ray spectroscopy (EDS) or electron diffraction. Use your imagination!\n",
    "\n",
    "This spatial map is represented by a 50x50 grid of pixels. To make it interesting, our experimentals failed in 25% of cases, leaving us with some unknown pixels (0 values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "EK8CFrv6dn_L",
    "outputId": "ffdd182b-56f2-46eb-d433-53d637ccdc51",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter  # Gaussian filter for image processing\n",
    "\n",
    "# Set image size and missing ratio\n",
    "image_size = (50, 50)  # 50x50 pixels\n",
    "missing_ratio = 0.25   # 25% missing pixels\n",
    "\n",
    "def generate_image_with_missing_pixels(image_size, mean=128, std=50):\n",
    "    \n",
    "    # Generate pixel values from a normal distribution\n",
    "    image_raw = np.random.normal(mean, std, size=image_size).astype(np.uint8)\n",
    "    # Apply Gaussian filter to mimic short-range order\n",
    "    sigma = 1  # adjust the standard deviation of the filter\n",
    "    image = gaussian_filter(image_raw, sigma=sigma)\n",
    "    # Clip values to ensure they are within the valid range [1, 255]\n",
    "    image = np.clip(image, 1, 255)\n",
    "    ground_truth = image.copy()\n",
    "    # Calculate the number of missing pixels\n",
    "    num_missing_pixels = int(image_size[0] * image_size[1] * missing_ratio)\n",
    "    # Generate random pixel coordinates for missing pixels\n",
    "    missing_indices = np.random.choice(image_size[0] * image_size[1], size=num_missing_pixels, replace=False)\n",
    "    # Set the missing pixels to black (0)\n",
    "    image_flat = image.reshape(-1)  # Flatten the image\n",
    "    image_flat[missing_indices] = 0\n",
    "    # Reshape the image back to the original shape\n",
    "    image = image_flat.reshape(image_size)\n",
    "\n",
    "    return image, ground_truth\n",
    "\n",
    "# Generate an example using the generate_image function\n",
    "sample_image, ground_truth = generate_image_with_missing_pixels(image_size)\n",
    "\n",
    "# Display the original image, image with missing pixels, and ground truth\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(ground_truth, vmin=0, vmax=255)\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(sample_image, vmin=0, vmax=255)\n",
    "plt.title('Image with Missing Pixels')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "missing_pixels = ground_truth - sample_image\n",
    "plt.imshow(missing_pixels, vmin=0, vmax=255)\n",
    "plt.title('Missing Pixels (Difference)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fsT0dQcdn_M",
    "tags": []
   },
   "source": [
    "## üö® Exercise 6: Heterogeneous materials\n",
    "\n",
    "```{admonition} Coding exercises\n",
    ":class: note\n",
    "The exercises are designed to apply what you have learned with room for creativity. It is fine to discuss solutions with your classmates, but the actual code should not be directly copied.\n",
    "\n",
    "The completed notebooks are to be submitted at the end of class, but you can revist later, experiment with the code, and follow the further reading suggestions.\n",
    "```\n",
    "\n",
    "### Your details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFysxI6Hdn_M",
    "outputId": "8c9f6a76-d393-44c4-d0d9-abb098c43eb9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Insert your values\n",
    "Name = \"Your name\"\n",
    "CID = 123446 # Replace with your College ID (as a numeric value with no leading 0s)\n",
    "\n",
    "# Set a random seed using the CID value\n",
    "CID = int(CID)\n",
    "np.random.seed(CID)\n",
    "\n",
    "# Print the message\n",
    "print(\"This is the work of \" + Name + \" [CID: 0\" + str(CID) + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDJlZ_A7dn_M"
   },
   "source": [
    "### Model\n",
    "\n",
    "In this exercise, the goal is to optimise a neural network that can predict the missing values (representing the local property) for each input image. The regression model involves four stages:\n",
    "\n",
    "1. **Data generation**: A synthetic dataset of 50x50 pixel images and their corresponding labels (ground truth).\n",
    "\n",
    "2. **Model creation**: A simple CNN in PyTorch, responsible for predicting the missing values.\n",
    "\n",
    "3. **Training**: Minimise the (MSE) loss between the predicted and the ground truth values.\n",
    "\n",
    "4. **Evaluation**: Evaluate the model's performance on an unseen test image.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "You will now improve the model performance from the current settings (loss of 0.0012). This can be achieved using different hyperparameters and training strategies to achieve the best results. But let's break it down and focus on delivering one task:\n",
    "\n",
    "1. **Learning Rate**: To improve training, adjust the learning rate from the default value of `lr=0.25` to find the optimal value.\n",
    "\n",
    "*Self-study (optional)*  \n",
    "\n",
    "2. **Optimiser**: Experiment with an alternative optimiser to enhance training. While you're currently using the SGD optimiser (`optim.SGD`), you can switch to another such as Adam (`optim.Adam`). Note that different optimisers may require different learning rates for best performance.\n",
    "\n",
    "The *target metric* is to achieve a lower Mean Squared Error (MSE) on the test dataset, indicating more accurate predictions, under the constraints of a fixed number of images (500) and epochs (5). Remember to document the changes made during optimisation to track progress effectively. You could do this in the form of commented lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "G3Z0ajQCdn_M",
    "outputId": "c8602a0e-a382-45ce-ffde-694a1b3e559a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorch deep learning library\n",
    "import torch.nn as nn  # Neural network modules in PyTorch\n",
    "import torch.optim as optim  # Optimisation algorithms in PyTorch\n",
    "\n",
    "torch.manual_seed(102)\n",
    "np.random.seed(102)\n",
    "\n",
    "# Set of images with missing pixels and their corresponding ground truth\n",
    "num_images = 500 # 500 training images \n",
    "image_pairs = [generate_image_with_missing_pixels(image_size) for _ in range(num_images)]\n",
    "\n",
    "# Convert the images to PyTorch tensors and normalise inputs only\n",
    "images_with_missing_pixels = [torch.from_numpy(image[0]).unsqueeze(0).unsqueeze(0).float() / 255.0 for image in image_pairs]\n",
    "ground_truth_images = [torch.from_numpy(image[1]).unsqueeze(0).unsqueeze(0).float() / 255.0 for image in image_pairs]\n",
    "\n",
    "# Define a simple CNN model for pixel prediction\n",
    "class PixelPredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelPredictionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Kernel size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 1, kernel_size=3, padding=1) # Kernel size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialise the model and define a loss function (Mean Squared Error) and an optimiser\n",
    "model = PixelPredictionModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.25) # Optimiser and learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5 # 5 epochs \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for image, ground_truth in zip(images_with_missing_pixels, ground_truth_images):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss / len(images_with_missing_pixels):.4f}')\n",
    "\n",
    "# Test the model by generating a sample image with missing pixels and reconstructing it\n",
    "sample_image, ground_truth = generate_image_with_missing_pixels(image_size)\n",
    "sample_image_tensor = torch.from_numpy(sample_image).unsqueeze(0).unsqueeze(0).float() / 255.0\n",
    "reconstructed_image = model(sample_image_tensor).squeeze().detach().numpy() * 255.0\n",
    "\n",
    "# Convert the ground truth image to a tensor for display\n",
    "ground_truth_tensor = torch.from_numpy(ground_truth).unsqueeze(0).unsqueeze(0).float() / 255.0\n",
    "\n",
    "# Display the original, reconstructed, and ground truth images\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(sample_image, vmin=0, vmax=255)\n",
    "plt.title('Input')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(reconstructed_image, vmin=0, vmax=255)\n",
    "plt.title('Reconstructed')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(ground_truth, vmin=0, vmax=255)\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Task hint </summary>\n",
    "One approach is to set `lr=rate` and loop over several values of the variable `rate`\n",
    "</details>\n",
    "\n",
    "```{admonition} Submission\n",
    ":class: note\n",
    "When your notebook is complete, click on the download icon on the top right, select `.pdf`, save the file and upload it to MyDepartment. If you are using Google Colab, you have to print to pdf.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Code block \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment block \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code block \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment block \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåä Dive deeper\n",
    "\n",
    "* _Level 1:_ Tackle Chapter 13 on Neural Networks in [Machine Learning Refined](https://github.com/jermwatt/machine_learning_refined#what-is-new-in-the-second-edition).\n",
    "\n",
    "* _Level 2:_ Watch [What is a Neural Net](https://www.youtube.com/watch?v=aircAruvnKk) video by 3Blue1Brown.\n",
    "\n",
    "* _Level 3:_ Cutting edge chapters and examples in [Understanding Deep Learning](https://udlbook.github.io/udlbook)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
